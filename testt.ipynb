{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "def check(strr):\n",
    "    my_re = re.compile(r'[A-Za-z]', re.S)\n",
    "    res = re.findall(my_re, strr)\n",
    "    if len(res):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def dataset(filepath):\n",
    "    nname = []\n",
    "    iinformation = []\n",
    "    with open(filepath, 'r+') as f:\n",
    "        readers = csv.reader(f, delimiter=\",\")\n",
    "        x = list(readers)[1:]\n",
    "        data = np.array(x)\n",
    "        for line in data:\n",
    "            nname.append(line[0])\n",
    "            iinformation.append([np.double(line[i]) for i in range(1, len(line))])\n",
    "        return nname, iinformation\n",
    "\n",
    "\n",
    "def test_one(file_path):\n",
    "    pdf = pdfplumber.open(file_path)\n",
    "    page = pdf.pages[0]\n",
    "    word = page.extract_words(y_tolerance=-1)\n",
    "\n",
    "    with open(\"output_csv/\" + pdf.metadata['Title'] + \".csv\", 'w', newline='') as f:\n",
    "        row = list(word[0].keys())[0:6]\n",
    "        row.pop(3)\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(row)\n",
    "        for wword in word:\n",
    "            if check(wword['text']):\n",
    "                continue\n",
    "            # row = list(wword.values())[0:6]\n",
    "            # write = csv.writer(f)\n",
    "            # write.writerow(row)\n",
    "            elif wword['text'].__contains__('.'):\n",
    "                row = list(wword.values())[0:6]\n",
    "                row.pop(3)\n",
    "                write = csv.writer(f)\n",
    "                write.writerow(row)\n",
    "\n",
    "    name, information = dataset(\"output_csv/\" + pdf.metadata['Title'] + \".csv\")\n",
    "\n",
    "    X = StandardScaler().fit_transform(information)\n",
    "    db = DBSCAN(eps=0.3,min_samples=3).fit(X)\n",
    "    # print(name)\n",
    "    # print(db.labels_)\n",
    "    # print(db.core_sample_indices_)\n",
    "\n",
    "    date = pd.read_csv(\"output_csv/\" + pdf.metadata['Title'] + \".csv\")\n",
    "    # print(date)\n",
    "    # print(db.labels_)\n",
    "    date['label'] = db.labels_\n",
    "    date.to_csv(\"output_csv/\" + pdf.metadata['Title'] + \".csv\",index=False)\n",
    "    # print(pd.read_csv(\"output_csv/\" + pdf.metadata['Title'] + \".csv\"))\n",
    "\n",
    "    # 读取数据文件\n",
    "    df = pd.read_csv(\"output_csv/\" + pdf.metadata['Title'] + \".csv\")\n",
    "    # print(df['text'][0]>0)\n",
    "\n",
    "    # 创建结果表\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    # 过滤掉最上面的小数\n",
    "    position = [\n",
    "                [ each / page.height < 1 / 8.3 for each in df['doctop']],\n",
    "                [each == -1 for each in df['label']]\n",
    "                ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    # result['厚度'] = df[booll]['text'].to_numpy()\n",
    "    df.drop(index=df[booll]['text'].index, inplace=True)\n",
    "\n",
    "    # 厚度\n",
    "    position = [[each/page.width <2.6/11.5 for each in df['x0']],\n",
    "            [1/2<each/page.height < 7.1/8.3 for each in df['doctop']],\n",
    "            [each > -1 for each in df['label']]\n",
    "            ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    result['厚度'] = df[booll]['text'].to_numpy()\n",
    "    df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    # 外边长\n",
    "    position = [[each/page.width <4.5/11.5 for each in df['x0']],\n",
    "            [each/page.height <3.2/8.6 for each in df['doctop']]\n",
    "            ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    result = pd.concat([result,pd.DataFrame({'外边长':df[booll]['text'].to_numpy()})],axis=1)\n",
    "    df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    # EXPOSED_PAD宽度\n",
    "    position = [[each/page.width >8/11.5 for each in df['x0']],\n",
    "            [2.5/9.2< each/page.height <7/9.2 for each in df['doctop']],\n",
    "                [each > -1 for each in df['label']]\n",
    "            ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    result = pd.concat([result,pd.DataFrame({'EXPOSED_PAD宽度':df[booll]['text'].to_numpy()})],axis=1)\n",
    "    df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    # 脚长度\n",
    "    position = [[4/12.5< each/page.width <8/12 for each in df['x0']],\n",
    "            [1/2< each/page.height <7/8.7 for each in df['doctop']],\n",
    "                [each > -1 for each in df['label']]\n",
    "            ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    result = pd.concat([result,pd.DataFrame({'脚长度':df[booll]['text'].to_numpy()})],axis=1)\n",
    "    df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    # 脚宽度1\n",
    "    position = [[2/11.4< each/page.width <5.5/11.4 for each in df['x0']],\n",
    "            [6/8.4< each/page.height  for each in df['doctop']],\n",
    "                [each > -1 for each in df['label']]\n",
    "            ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    result = pd.concat([result,pd.DataFrame({'脚宽度':df[booll]['text'].to_numpy()})],axis=1)\n",
    "    df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "    # print(df)\n",
    "\n",
    "    # # EXPOSED_PAD长度\n",
    "    # position = [[6.5/11.4< each/page.width <9.5/11.4 for each in df['x0']],\n",
    "    #         [1/8< each/page.height <4/8.7 for each in df['doctop']],\n",
    "    #             [each > -1 for each in df['label']]\n",
    "    #         ]\n",
    "    # booll = [all(e) for e in zip(*position)]\n",
    "    # result = pd.concat([result,pd.DataFrame({'EXPOSED_PAD长度':df[booll]['text'].to_numpy()})],axis=1)\n",
    "    # df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    # 脚宽度2\n",
    "    position = [[4.5 / 10.7 < each / page.width < 9 / 12 for each in df['x0']],\n",
    "                [1.5 / 8.8 < each / page.height < 4 / 8.7 for each in df['doctop']],\n",
    "                [each > -1 for each in df['label']]\n",
    "                ]\n",
    "    booll = [all(e) for e in zip(*position)]\n",
    "    print(float(df[booll]['text'].head(1).to_numpy()))\n",
    "    if df[booll]['text'].head(1).to_numpy()>1:\n",
    "        result = pd.concat([result, pd.DataFrame({'EXPOSED_PAD长度': df[booll]['text'].to_numpy()})], axis=1)\n",
    "    else:\n",
    "        result = pd.concat([result, pd.DataFrame({'脚宽度': df[booll]['text'].to_numpy()})], axis=1)\n",
    "\n",
    "    df.drop(index=df[booll]['text'].index, inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        pass\n",
    "    else:\n",
    "        #脚间距\n",
    "        position = [\n",
    "            [ each/page.height <4.5/8.4 for each in df['doctop']],\n",
    "                [each == -1 for each in df['label']]\n",
    "            ]\n",
    "        booll = [all(e) for e in zip(*position)]\n",
    "        result = pd.concat([result,pd.DataFrame({'脚间距':df[booll]['text'].to_numpy()})],axis=1)\n",
    "        df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        pass\n",
    "    else:\n",
    "         #拐角限制\n",
    "        position = [[8/12< each/page.width for each in df['x0']],\n",
    "            [ 4.5/8.4< each/page.height  for each in df['doctop']],\n",
    "                [each == -1 for each in df['label']]\n",
    "            ]\n",
    "        booll = [all(e) for e in zip(*position)]\n",
    "        result = pd.concat([result,pd.DataFrame({'拐角限制':df[booll]['text'].to_numpy()})],axis=1)\n",
    "        df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        pass\n",
    "    else:# 剩余side view参数\n",
    "        df = df.sort_values('doctop')\n",
    "        position = [\n",
    "            [5.5/8.7< each/page.height for each in df['doctop']],\n",
    "                [each == -1 for each in df['label']]\n",
    "            ]\n",
    "        booll = [all(e) for e in zip(*position)]\n",
    "        side_view = df[booll]['text']\n",
    "        df.drop(index=df[booll]['text'].index,inplace=True)\n",
    "        result = pd.concat([result,pd.DataFrame({'芯片底到pcb最大距离':side_view[0:1].to_numpy()})],axis=1)\n",
    "        side_view.drop(index=side_view[0:1].index,inplace=True)\n",
    "        result = pd.concat([result,pd.DataFrame({'芯片底到pcb标准距离':side_view[0:1].to_numpy()})],axis=1)\n",
    "        side_view.drop(index=side_view[0:1].index,inplace=True)\n",
    "        result = pd.concat([result,pd.DataFrame({'针脚到pcb距离':side_view.tail(1).to_numpy()})],axis=1)\n",
    "        side_view.drop(index=side_view.tail(1).index,inplace=True)\n",
    "        result = pd.concat([result,pd.DataFrame({'COPLANARITY':side_view.to_numpy()})],axis=1)\n",
    "        result = pd.concat([result,pd.DataFrame({'未分类':df['text'].to_numpy()})],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    result.to_csv(\"result_csv/\" + pdf.metadata['Title'] + \".csv\",index=False,encoding='utf-8-sig')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "def separate(filepath,page):\n",
    "    # 读取数据文件\n",
    "    df = pd.read_csv(filepath)\n",
    "    # print([100<each<140 for each in df['x0']])\n",
    "\n",
    "    # 创建结果表\n",
    "    result = pd.read_csv()\n",
    "\n",
    "    # 厚度\n",
    "    data = [[each/page.width <3.5/11.5 for each in df['x0']],\n",
    "            [each/page.height >1/2 for each in df['doctop']],\n",
    "            [each > 0 for each in df['label']]\n",
    "            ]\n",
    "    booll = [all(e) for e in zip(*data)]\n",
    "    result['厚度'] = df[booll]['text']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [28]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata_pdf/cp-16-40.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtest_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36mtest_one\u001B[1;34m(file_path)\u001B[0m\n\u001B[0;32m    147\u001B[0m booll \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mall\u001B[39m(e) \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mposition)]\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mfloat\u001B[39m(df[booll][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto_numpy()))\n\u001B[1;32m--> 149\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbooll\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m:\n\u001B[0;32m    150\u001B[0m     result \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([result, pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEXPOSED_PAD长度\u001B[39m\u001B[38;5;124m'\u001B[39m: df[booll][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto_numpy()})], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"data_pdf/cp-16-40.pdf\"\n",
    "test_one(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}